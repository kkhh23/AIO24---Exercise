{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import re\n",
      "import string\n",
      "import nltk\n",
      "nltk . download (’stopwords ’)\n",
      "nltk . download (’wordnet ’)\n",
      "from nltk . corpus import stopwords\n",
      "from nltk . stem import WordNetLemmatizer\n",
      "from bs4 import BeautifulSoup\n",
      "import contractions\n",
      "stop = set( stopwords . words (’english ’))\n",
      "# Expanding contractions\n",
      "def expand_contractions ( text ) :\n",
      "return contractions . fix( text )\n",
      "# Function to clean data\n",
      "def preprocess_text ( text ) :\n",
      "wl = WordNetLemmatizer ()\n",
      "soup = BeautifulSoup (text , \" html . parser \") # Removing html tags\n",
      "text = soup . get_text ()\n",
      "text = expand_contractions ( text ) # Expanding chatwords and contracts clearing\n",
      "contractions\n",
      "emoji_clean = re. compile (\"[\"\n",
      "u\"\\ U0001F600 -\\ U0001F64F \" # emoticons\n",
      "u\"\\ U0001F300 -\\ U0001F5FF \" # symbols & pictographs\n",
      "u\"\\ U0001F680 -\\ U0001F6FF \" # transport & map symbols\n",
      "u\"\\ U0001F1E0 -\\ U0001F1FF \" # flags (iOS)\n",
      "u\"\\ U00002702 -\\ U000027B0 \"\n",
      "u\"\\ U000024C2 -\\ U0001F251 \"\n",
      "\"]+\", flags =re. UNICODE )\n",
      "text = emoji_clean . sub(r’’,text )\n",
      "text = re.sub (r’\\.(?=\\ S)’, ’. ’,text ) #add space after full stop\n",
      "text = re.sub (r’http \\S+’, ’’, text ) # remove urls\n",
      "text = \"\". join ([\n",
      "word . lower () for word in text if word not in string . punctuation\n",
      "]) # remove punctuation and make text lowercase\n",
      "text = \" \". join ([\n",
      "wl. lemmatize ( word ) for word in text . split () if word not in stop and word .\n",
      "isalpha () ]) # lemmatize\n",
      "return text\n",
      "df[’review ’] = df[’review ’]. apply ( preprocess_text )\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14320\\2714876737.py:9: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  code_string = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "importre\n",
    "\n",
    "defremove_leading_numbers(input_string):\n",
    "#Useregularexpressiontoremovenumbersatthestartofeachline\n",
    "result=re.sub(r'^\\d+\\s+','',input_string,flags=re.MULTILINE)\n",
    "returnresult\n",
    "\n",
    "#Exampleusage\n",
    "code_string=\"\"\"\n",
    "importre\n",
    "2importstring\n",
    "3importnltk\n",
    "4nltk.download(’stopwords’)\n",
    "5nltk.download(’wordnet’)\n",
    "6fromnltk.corpusimportstopwords\n",
    "7fromnltk.stemimportWordNetLemmatizer\n",
    "8frombs4importBeautifulSoup\n",
    "9importcontractions\n",
    "10\n",
    "11stop=set(stopwords.words(’english’))\n",
    "12\n",
    "13#Expandingcontractions\n",
    "14defexpand_contractions(text):\n",
    "15returncontractions.fix(text)\n",
    "16\n",
    "17#Functiontocleandata\n",
    "18defpreprocess_text(text):\n",
    "19\n",
    "20wl=WordNetLemmatizer()\n",
    "21\n",
    "22soup=BeautifulSoup(text,\"html.parser\")#Removinghtmltags\n",
    "23text=soup.get_text()\n",
    "24text=expand_contractions(text)#Expandingchatwordsandcontractsclearing\n",
    "contractions\n",
    "25emoji_clean=re.compile(\"[\"\n",
    "26u\"\\U0001F600-\\U0001F64F\"#emoticons\n",
    "27u\"\\U0001F300-\\U0001F5FF\"#symbols&pictographs\n",
    "28u\"\\U0001F680-\\U0001F6FF\"#transport&mapsymbols\n",
    "29u\"\\U0001F1E0-\\U0001F1FF\"#flags(iOS)\n",
    "30u\"\\U00002702-\\U000027B0\"\n",
    "31u\"\\U000024C2-\\U0001F251\"\n",
    "32\"]+\",flags=re.UNICODE)\n",
    "33text=emoji_clean.sub(r’’,text)\n",
    "34text=re.sub(r’\\.(?=\\S)’,’.’,text)#addspaceafterfullstop\n",
    "35text=re.sub(r’http\\S+’,’’,text)#removeurls\n",
    "36text=\"\".join([\n",
    "37word.lower()forwordintextifwordnotinstring.punctuation\n",
    "38])#removepunctuationandmaketextlowercase\n",
    "39text=\"\".join([\n",
    "40wl.lemmatize(word)forwordintext.split()ifwordnotinstopandword.\n",
    "isalpha()])#lemmatize\n",
    "41returntext\n",
    "42\n",
    "43df[’review’]=df[’review’].apply(preprocess_text)\n",
    "\"\"\"\n",
    "\n",
    "cleaned_string=remove_leading_numbers(code_string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u\"\\U0001F600-\\U0001F64F\"#emoticons\n",
    "u\"\\U0001F300-\\U0001F5FF\"#symbols&pictographs\n",
    "u\"\\U0001F680-\\U0001F6FF\"#transport&mapsymbols\n",
    "u\"\\U0001F1E0-\\U0001F1FF\"#flags(iOS)\n",
    "u\"\\U00002702-\\U000027B0\"\n",
    "u\"\\U000024C2-\\U0001F251\"\n",
    "\"]+\",flags=re.UNICODE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
