{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.is_available ()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"lsh7WBbsoSIf"},"outputs":[],"source":["from ultralytics import YOLOv10\n","# MODEL_PATH = 'yolov10n.pt'\n","MODEL_PATH = r'D:\\AIO_2024_main_class\\1.4. Excercise Git\\AIO24---Exercise\\project_yolo_v10\\runs\\detect\\train15\\weights\\best.pt'\n","model = YOLOv10(MODEL_PATH)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1082,"status":"ok","timestamp":1718996163332,"user":{"displayName":"Th·∫Øng D∆∞∆°ng","userId":"16346474942041582373"},"user_tz":-420},"id":"lmWHCtYvoSK6","outputId":"cf72cd84-44a7-40b1-c674-11b507e2c213"},"outputs":[{"name":"stdout","output_type":"stream","text":["YOLOv10n summary: 385 layers, 2708210 parameters, 0 gradients\n"]},{"data":{"text/plain":["(385, 2708210, 0, 0.0)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.info()"]},{"cell_type":"markdown","metadata":{"id":"H7hz5zcqo4L-"},"source":["### Training"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1186512,"status":"ok","timestamp":1718978601530,"user":{"displayName":"Th·∫Øng D∆∞∆°ng","userId":"16346474942041582373"},"user_tz":-420},"id":"8DUOCO0ksEW_","outputId":"46040b31-3001-4e05-c236-864f04f4be26"},"outputs":[{"name":"stdout","output_type":"stream","text":["New https://pypi.org/project/ultralytics/8.2.50 available üòÉ Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.1.34 üöÄ Python-3.12.3 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 Ti, 4096MiB)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=D:\\AIO_2024_main_class\\1.4. Excercise Git\\AIO24---Exercise\\project_yolo_v10\\runs\\detect\\train15\\weights\\best.pt, data=../safety_helmet_dataset/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=d:\\AIO_2024_main_class\\1.4. Excercise Git\\AIO24---Exercise\\runs\\detect\\train3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n"," 23        [16, 19, 22]  1    862498  ultralytics.nn.modules.head.v10Detect        [3, [64, 128, 256]]           \n","YOLOv10n summary: 385 layers, 2708210 parameters, 2708194 gradients\n","\n","Transferred 595/595 items from pretrained weights\n"]}],"source":["YAML_PATH = '../safety_helmet_dataset/data.yaml'\n","EPOCHS = 50\n","IMG_SIZE = 640\n","BATCH_SIZE = 16\n","\n","model.train(data=YAML_PATH,\n","            epochs=EPOCHS,\n","            batch=BATCH_SIZE,\n","            imgsz=IMG_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"VlCU_cuilvjj"},"source":["## Evaluate model"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["'d:\\\\AIO_2024_main_class\\\\1.4. Excercise Git\\\\AIO24---Exercise\\\\project_yolo_v10'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","\n","# Get the current directory\n","current_directory = os.getcwd()\n","current_directory"]},{"cell_type":"markdown","metadata":{"id":"TQGwE9Cmlx1K"},"source":["## Run prediction with an image"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718979026011,"user":{"displayName":"Th·∫Øng D∆∞∆°ng","userId":"16346474942041582373"},"user_tz":-420},"id":"ydtxm5HHIk0Q","outputId":"d1578978-9a3b-4e7a-b910-d401051c659c"},"outputs":[],"source":["# https://github.com/googlecolab/colabtools/issues/3409\n","import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":895},"executionInfo":{"elapsed":1484,"status":"ok","timestamp":1718979203815,"user":{"displayName":"Th·∫Øng D∆∞∆°ng","userId":"16346474942041582373"},"user_tz":-420},"id":"nfFjjKcgXouz","outputId":"ae8726b2-4a65-4ec8-9e89-33cdc7173e61"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Found https://ips-dc.org/wp-content/uploads/2022/05/Black-Workers-Need-a-Bill-of-Rights.jpeg locally at Black-Workers-Need-a-Bill-of-Rights.jpeg\n","image 1/1 d:\\AIO_2024_main_class\\1.4. Excercise Git\\AIO24---Exercise\\project_yolo_v10\\Black-Workers-Need-a-Bill-of-Rights.jpeg: 448x640 (no detections), 64.1ms\n","Speed: 5.1ms preprocess, 64.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n"]}],"source":["# from google.colab.patches import cv2_imshow\n","from ultralytics import YOLOv10\n","import cv2\n","import requests\n","import numpy as np\n","TRAINED_MODEL_PATH = r'D:\\AIO_2024_main_class\\1.4. Excercise Git\\AIO24---Exercise\\project_yolo_v10\\runs\\detect\\train15\\weights\\best.pt'\n","model = YOLOv10(TRAINED_MODEL_PATH)\n","IMG_SIZE = 640\n","IMAGE_URL = 'https://ips-dc.org/wp-content/uploads/2022/05/Black-Workers-Need-a-Bill-of-Rights.jpeg'\n","# T·∫£i h√¨nh ·∫£nh t·ª´ URL\n","response = requests.get(IMAGE_URL)\n","image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n","image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n","CONF_THRESHOLD = 0\n","results = model.predict(source=IMAGE_URL,\n","                       imgsz=IMG_SIZE,\n","                       conf=CONF_THRESHOLD)\n","annotated_img = results[0].plot()\n","annotated_img \n","for result in results:\n","    for detection in result.boxes:\n","        x1, y1, x2, y2 = map(int, detection.xyxy[0])  # L·∫•y t·ªça ƒë·ªô bounding box\n","        label = detection.cls[0]  # L·∫•y nh√£n\n","        conf = detection.conf[0]  # L·∫•y ƒë·ªô tin c·∫≠y\n","\n","        # V·∫Ω bounding box\n","        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","        \n","        # Hi·ªÉn th·ªã nh√£n v√† ƒë·ªô tin c·∫≠y\n","        cv2.putText(image, f'{label} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n","cv2.imwrite(annotated_img, image)\n","cv2.imshow('Predicted Image', annotated_img)\n","# original_image_path = 'original_image.jpg'\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["ultralytics.engine.results.Boxes object with attributes:\n","\n","cls: tensor([], device='cuda:0')\n","conf: tensor([], device='cuda:0')\n","data: tensor([], device='cuda:0', size=(0, 6))\n","id: None\n","is_track: False\n","orig_shape: (667, 1000)\n","shape: torch.Size([0, 6])\n","xywh: tensor([], device='cuda:0', size=(0, 4))\n","xywhn: tensor([], device='cuda:0', size=(0, 4))\n","xyxy: tensor([], device='cuda:0', size=(0, 4))\n","xyxyn: tensor([], device='cuda:0', size=(0, 4))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["results[0].boxes"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
